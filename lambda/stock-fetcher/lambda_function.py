# lambda/stock_fetcher/lambda_function.py
"""
Lambda Function para coletar dados de cota√ß√µes de a√ß√µes da Alpha Vantage API
e salvar no Amazon S3 - Vers√£o Produ√ß√£o.
"""

import json
import os
import sys
import boto3
import requests
from datetime import datetime, timezone
import time
import logging
from typing import Dict, List, Any, Optional
import hashlib

# Adicionar diret√≥rio atual ao path para importar m√≥dulos locais
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# ===== CONFIGURA√á√ÉO DE LOGGING =====
def setup_logging():
    """Configura logging consistente para AWS e local"""
    logger = logging.getLogger()
    
    # Remove handlers existentes
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # Configurar formato
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Handler para console
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # N√≠vel baseado em ambiente
    if os.environ.get('AWS_EXECUTION_ENV'):
        logger.setLevel(logging.INFO)  # Produ√ß√£o
    else:
        logger.setLevel(logging.DEBUG)  # Desenvolvimento
    
    return logger

logger = setup_logging()

# ===== VALIDA√á√ÉO DE VARI√ÅVEIS DE AMBIENTE =====
def validate_environment():
    """Valida e obt√©m vari√°veis de ambiente cr√≠ticas"""
    # API Key - OBRIGAT√ìRIA
    api_key = os.environ.get('ALPHA_VANTAGE_API_KEY')
    if not api_key or api_key == 'demo':
        logger.error("‚ùå ALPHA_VANTAGE_API_KEY n√£o configurada ou est√° como 'demo'")
        logger.error("Configure a vari√°vel de ambiente com sua chave real da Alpha Vantage")
        raise ValueError("ALPHA_VANTAGE_API_KEY √© obrigat√≥ria")
    
    # Validar formato da API key (Alpha Vantage keys s√£o normalmente 16 caracteres)
    if len(api_key) < 10:
        logger.warning(f"‚ö†Ô∏è  API key muito curta: {len(api_key)} caracteres")
    
    # S3 Bucket - OBRIGAT√ìRIO
    bucket_name = os.environ.get('S3_BUCKET_NAME')
    if not bucket_name:
        logger.error("‚ùå S3_BUCKET_NAME n√£o configurada")
        raise ValueError("S3_BUCKET_NAME √© obrigat√≥ria")
    
    # Validar nome do bucket (regras S3)
    if len(bucket_name) < 3 or len(bucket_name) > 63:
        logger.error(f"‚ùå Nome do bucket inv√°lido: deve ter entre 3 e 63 caracteres")
        raise ValueError("Nome do bucket inv√°lido")
    
    # Log seguro
    api_key_display = f"{api_key[:4]}...{api_key[-4:]}" if len(api_key) > 8 else "***"
    logger.info(f"‚úÖ API Key: {api_key_display}")
    logger.info(f"‚úÖ S3 Bucket: {bucket_name}")
    
    return api_key, bucket_name

try:
    ALPHA_VANTAGE_API_KEY, S3_BUCKET_NAME = validate_environment()
except ValueError as e:
    logger.critical(f"Falha na valida√ß√£o: {e}")
    logger.critical("Para desenvolvimento local, configure as vari√°veis:")
    logger.critical("  export ALPHA_VANTAGE_API_KEY='sua_key_real'")
    logger.critical("  export S3_BUCKET_NAME='stock-quotes-data'")
    sys.exit(1)

# ===== INICIALIZA√á√ÉO DE CLIENTES =====
class AWSClientManager:
    """Gerencia clientes AWS com tratamento de erros"""
    
    @staticmethod
    def get_s3_client():
        """Retorna cliente S3 configurado"""
        try:
            # Para Lambda, usa IAM Role automaticamente
            # Para local, usa credenciais do ~/.aws/credentials
            client = boto3.client('s3')
            
            # Testar conex√£o (opera√ß√£o leve)
            client.list_buckets()
            logger.info("‚úÖ Cliente S3 inicializado com sucesso")
            return client
        
        except Exception as e:
            logger.error(f"‚ùå Falha ao inicializar cliente S3: {str(e)}")
            
            # Verificar se √© ambiente local
            if not os.environ.get('AWS_EXECUTION_ENV'):
                logger.info("üí° Dica para ambiente local:")
                logger.info("  1. Instale AWS CLI: https://aws.amazon.com/cli/")
                logger.info("  2. Configure: aws configure")
                logger.info("  3. Ou defina AWS_ACCESS_KEY_ID e AWS_SECRET_ACCESS_KEY")
            
            raise

# Inicializar clientes
try:
    s3_client = AWSClientManager.get_s3_client()
except Exception:
    # Em √∫ltimo caso, criar um cliente b√°sico (pode falhar depois)
    s3_client = boto3.client('s3')
    logger.warning("‚ö†Ô∏è  Usando cliente S3 sem valida√ß√£o inicial")

# ===== IMPORTAR LISTA DE EMPRESAS =====
try:
    from company_list import get_all_symbols, COMPANIES
    logger.info(f"‚úÖ Importado company_list com {len(COMPANIES)} empresas")
except ImportError as e:
    logger.critical(f"‚ùå Falha ao importar company_list: {e}")
    raise

# ===== CLASSE ALPHA VANTAGE API =====
class AlphaVantageAPI:
    """Cliente robusto para Alpha Vantage API"""
    
    BASE_URL = "https://www.alphavantage.co/query"
    RATE_LIMIT_DELAY = 12.1  # 12.1 segundos entre requisi√ß√µes (5/min free tier)
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'StockDataPipeline/1.0',
            'Accept': 'application/json'
        })
        self.last_request_time = 0
    
    def _respect_rate_limit(self):
        """Respeita rate limit da API"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.RATE_LIMIT_DELAY:
            sleep_time = self.RATE_LIMIT_DELAY - time_since_last
            logger.debug(f"Rate limiting: aguardando {sleep_time:.1f}s")
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def _make_request(self, params: Dict) -> Optional[Dict]:
        """Faz requisi√ß√£o HTTP com tratamento de erros"""
        self._respect_rate_limit()
        
        try:
            logger.debug(f"Request: {params.get('function')} para {params.get('symbol', 'N/A')}")
            
            response = self.session.get(
                self.BASE_URL,
                params=params,
                timeout=30,
                verify=True  # Verificar SSL
            )
            
            response.raise_for_status()
            data = response.json()
            
            # Verificar erros da API
            if "Error Message" in data:
                logger.error(f"API Error: {data['Error Message']}")
                return None
            
            if "Note" in data:
                note = data["Note"]
                if "rate limit" in note.lower():
                    logger.warning(f"‚ö†Ô∏è  Rate limit detectado: {note}")
                    # Aumentar delay para pr√≥xima requisi√ß√£o
                    self.RATE_LIMIT_DELAY = 60  # 1 minuto
                else:
                    logger.info(f"API Note: {note}")
            
            return data
            
        except requests.exceptions.Timeout:
            logger.error("Timeout na requisi√ß√£o (30s)")
            return None
        except requests.exceptions.ConnectionError:
            logger.error("Erro de conex√£o")
            return None
        except requests.exceptions.HTTPError as e:
            logger.error(f"HTTP Error {e.response.status_code}: {e.response.text[:100]}")
            return None
        except json.JSONDecodeError:
            logger.error("Resposta n√£o √© JSON v√°lido")
            return None
        except Exception as e:
            logger.error(f"Erro inesperado: {str(e)}")
            return None
    
    def get_intraday_quotes(self, symbol: str) -> Optional[Dict]:
        """Busca cota√ß√µes intraday (5min interval)"""
        params = {
            "function": "TIME_SERIES_INTRADAY",
            "symbol": symbol,
            "interval": "5min",
            "apikey": self.api_key,
            "outputsize": "compact",
            "datatype": "json"
        }
        
        return self._make_request(params)
    
    def get_company_overview(self, symbol: str) -> Optional[Dict]:
        """Busca dados fundamentais"""
        params = {
            "function": "OVERVIEW",
            "symbol": symbol,
            "apikey": self.api_key
        }
        
        return self._make_request(params)

# ===== PROCESSADOR DE DADOS =====
class StockDataProcessor:
    """Processa e transforma dados brutos"""
    
    @staticmethod
    def extract_latest_quote(api_data: Dict, symbol: str) -> Optional[Dict]:
        """Extrai a cota√ß√£o mais recente"""
        try:
            time_series = api_data.get("Time Series (5min)", {})
            if not time_series:
                logger.warning(f"Sem dados de s√©rie temporal para {symbol}")
                return None
            
            # Encontrar timestamp mais recente
            latest_timestamp = max(time_series.keys())
            quote_data = time_series[latest_timestamp]
            
            # Converter valores
            quote = {
                "symbol": symbol,
                "timestamp": latest_timestamp,
                "price": float(quote_data.get("4. close", 0)),
                "volume": int(quote_data.get("5. volume", 0)),
                "open": float(quote_data.get("1. open", 0)),
                "high": float(quote_data.get("2. high", 0)),
                "low": float(quote_data.get("3. low", 0)),
                "close": float(quote_data.get("4. close", 0))
            }
            
            # Calcular varia√ß√µes
            if quote["open"] > 0:
                quote["change"] = quote["close"] - quote["open"]
                quote["change_percent"] = (quote["change"] / quote["open"]) * 100
            
            # Adicionar metadados da empresa
            company_info = COMPANIES.get(symbol, {})
            quote.update({
                "name": company_info.get("name", ""),
                "sector": company_info.get("sector", ""),
                "industry": company_info.get("industry", "")
            })
            
            logger.debug(f"Processado {symbol}: ${quote['price']:.2f}")
            return quote
            
        except Exception as e:
            logger.error(f"Erro ao processar quote de {symbol}: {str(e)}")
            return None
    
    @staticmethod
    def process_overview_data(api_data: Dict) -> Optional[Dict]:
        """Processa dados fundamentais"""
        try:
            if not api_data or "Symbol" not in api_data:
                return None
            
            processed = {
                "symbol": api_data.get("Symbol"),
                "name": api_data.get("Name", ""),
                "description": (api_data.get("Description", "")[:400] + "...") 
                              if len(api_data.get("Description", "")) > 400 
                              else api_data.get("Description", ""),
                "sector": api_data.get("Sector", ""),
                "industry": api_data.get("Industry", ""),
                "exchange": api_data.get("Exchange", ""),
                "currency": api_data.get("Currency", ""),
                "country": api_data.get("Country", ""),
                "market_cap": StockDataProcessor._safe_float(api_data.get("MarketCapitalization")),
                "pe_ratio": StockDataProcessor._safe_float(api_data.get("PERatio")),
                "dividend_yield": StockDataProcessor._safe_float(api_data.get("DividendYield")),
                "roe": StockDataProcessor._safe_float(api_data.get("ReturnOnEquityTTM")),
                "revenue_ttm": StockDataProcessor._safe_float(api_data.get("RevenueTTM")),
                "gross_profit_ttm": StockDataProcessor._safe_float(api_data.get("GrossProfitTTM")),
                "profit_margin": StockDataProcessor._safe_float(api_data.get("ProfitMargin")),
                "operating_margin": StockDataProcessor._safe_float(api_data.get("OperatingMarginTTM")),
                "eps": StockDataProcessor._safe_float(api_data.get("EPS")),
                "beta": StockDataProcessor._safe_float(api_data.get("Beta")),
                "52_week_high": StockDataProcessor._safe_float(api_data.get("52WeekHigh")),
                "52_week_low": StockDataProcessor._safe_float(api_data.get("52WeekLow")),
                "50_day_moving_avg": StockDataProcessor._safe_float(api_data.get("50DayMovingAverage")),
                "200_day_moving_avg": StockDataProcessor._safe_float(api_data.get("200DayMovingAverage")),
                "shares_outstanding": StockDataProcessor._safe_float(api_data.get("SharesOutstanding")),
                "analyst_target_price": StockDataProcessor._safe_float(api_data.get("AnalystTargetPrice")),
                "analyst_rating": api_data.get("AnalystRating", ""),
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
            
            return processed
            
        except Exception as e:
            logger.error(f"Erro ao processar overview: {str(e)}")
            return None
    
    @staticmethod
    def _safe_float(value: Any) -> Optional[float]:
        """Converte para float com seguran√ßa"""
        if not value or value in ["None", "N/A", "-"]:
            return None
        try:
            return float(str(value).replace(',', ''))
        except (ValueError, TypeError):
            return None

# ===== GERENCIADOR S3 =====
class S3DataManager:
    """Gerencia armazenamento no S3"""
    
    def __init__(self, bucket_name: str, s3_client):
        self.bucket_name = bucket_name
        self.s3_client = s3_client
    
    def save_quotes(self, quotes: List[Dict]) -> bool:
        """Salva cota√ß√µes no S3"""
        if not quotes:
            logger.warning("Nenhuma cota√ß√£o para salvar")
            return False
        
        try:
            current_time = datetime.now(timezone.utc)
            date_str = current_time.strftime("%Y-%m-%d")
            timestamp_str = current_time.strftime("%Y%m%d-%H%M%S")
            
            # Estrutura de dados
            data = {
                "metadata": {
                    "pipeline_version": "1.0",
                    "execution_timestamp": current_time.isoformat(),
                    "total_companies": len(quotes),
                    "data_type": "stock_quotes",
                    "source": "alpha_vantage"
                },
                "date": date_str,
                "quotes": quotes
            }
            
            # Gerar hash para integridade
            data_json = json.dumps(data, separators=(',', ':'))
            data_hash = hashlib.md5(data_json.encode()).hexdigest()[:8]
            
            s3_key = f"quotes/{date_str}/stock-quotes-{timestamp_str}-{data_hash}.json"
            
            # Upload para S3
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=s3_key,
                Body=data_json,
                ContentType='application/json',
                Metadata={
                    'total-companies': str(len(quotes)),
                    'data-hash': data_hash,
                    'pipeline-version': '1.0'
                }
            )
            
            logger.info(f"‚úÖ Cota√ß√µes salvas: s3://{self.bucket_name}/{s3_key}")
            logger.info(f"   Empresas: {len(quotes)}, Hash: {data_hash}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Falha ao salvar cota√ß√µes: {str(e)}")
            return False
    
    def save_fundamentals(self, fundamentals: List[Dict]) -> bool:
        """Salva dados fundamentais"""
        if not fundamentals:
            return False
        
        try:
            current_time = datetime.now(timezone.utc)
            date_str = current_time.strftime("%Y-%m-%d")
            
            data = {
                "metadata": {
                    "pipeline_version": "1.0",
                    "execution_timestamp": current_time.isoformat(),
                    "total_companies": len(fundamentals),
                    "data_type": "company_fundamentals"
                },
                "date": date_str,
                "companies": fundamentals
            }
            
            s3_key = f"fundamentals/{date_str}/company-fundamentals.json"
            
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=s3_key,
                Body=json.dumps(data, indent=2),
                ContentType='application/json'
            )
            
            logger.info(f"‚úÖ Fundamentais salvas: s3://{self.bucket_name}/{s3_key}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Falha ao salvar fundamentais: {str(e)}")
            return False

# ===== HANDLER PRINCIPAL =====
def lambda_handler(event, context) -> Dict:
    """
    Handler principal da Lambda Function
    """
    # In√≠cio da execu√ß√£o
    start_time = time.time()
    logger.info("üöÄ === INICIANDO PIPELINE DE DADOS ===")
    
    # Informa√ß√µes de execu√ß√£o
    if context:
        logger.info(f"Request ID: {context.aws_request_id}")
        logger.info(f"Function: {context.function_name}")
        logger.info(f"Memory: {context.memory_limit_in_mb}MB")
    
    # Inicializar componentes
    api_client = AlphaVantageAPI(ALPHA_VANTAGE_API_KEY)
    processor = StockDataProcessor()
    s3_manager = S3DataManager(S3_BUCKET_NAME, s3_client)
    
    # Obter empresas
    symbols = get_all_symbols()
    logger.info(f"üìä Empresas monitoradas: {len(symbols)}")
    logger.info(f"S√≠mbolos: {', '.join(symbols[:10])}{'...' if len(symbols) > 10 else ''}")
    
    # Verificar se deve coletar fundamentais
    current_time = datetime.now(timezone.utc)
    current_hour = current_time.hour
    current_minute = current_time.minute
    
    # Coletar fundamentais apenas ~9:30 AM EST (14:30 UTC)
    collect_fundamentals = (current_hour == 14 and current_minute <= 35)
    
    if collect_fundamentals:
        logger.info("‚≠ê Coletando dados fundamentais (primeira execu√ß√£o do dia)")
    
    # Coletar dados
    successful_quotes = []
    successful_fundamentals = []
    failed_symbols = []
    
    logger.info("üîÑ Iniciando coleta de dados...")
    
    for idx, symbol in enumerate(symbols, 1):
        try:
            logger.info(f"[{idx}/{len(symbols)}] Processando {symbol}")
            
            # 1. Coletar cota√ß√µes
            quote_data = api_client.get_intraday_quotes(symbol)
            
            if quote_data:
                quote = processor.extract_latest_quote(quote_data, symbol)
                if quote:
                    successful_quotes.append(quote)
                    
                    # Log resumido
                    change_str = f"Œî {quote.get('change_percent', 0):+.2f}%"
                    logger.info(f"   ‚úì ${quote['price']:.2f} ({change_str})")
                else:
                    failed_symbols.append(symbol)
                    logger.warning(f"   ‚úó Sem dados de cota√ß√£o")
            else:
                failed_symbols.append(symbol)
                logger.warning(f"   ‚úó Falha na API")
            
            # 2. Coletar fundamentais (se for hora)
            if collect_fundamentals:
                overview_data = api_client.get_company_overview(symbol)
                if overview_data:
                    fundamentals = processor.process_overview_data(overview_data)
                    if fundamentals:
                        successful_fundamentals.append(fundamentals)
                        logger.info(f"   ‚úì Fundamentais coletados")
            
            # Progresso
            if idx % 5 == 0:
                progress = (idx / len(symbols)) * 100
                logger.info(f"üìà Progresso: {progress:.1f}% ({idx}/{len(symbols)})")
                
        except Exception as e:
            failed_symbols.append(symbol)
            logger.error(f"   üí• Erro inesperado em {symbol}: {str(e)}")
            continue
    
    # Salvar dados
    save_results = {
        "quotes_saved": False,
        "fundamentals_saved": False
    }
    
    # Salvar cota√ß√µes
    if successful_quotes:
        save_results["quotes_saved"] = s3_manager.save_quotes(successful_quotes)
    
    # Salvar fundamentais
    if successful_fundamentals and collect_fundamentals:
        save_results["fundamentals_saved"] = s3_manager.save_fundamentals(successful_fundamentals)
    
    # Resumo da execu√ß√£o
    execution_time = time.time() - start_time
    logger.info("=" * 50)
    logger.info("üéØ === RESUMO DA EXECU√á√ÉO ===")
    logger.info(f"‚úÖ Sucessos: {len(successful_quotes)}/{len(symbols)} cota√ß√µes")
    logger.info(f"‚úÖ Fundamentais: {len(successful_fundamentals)} coletados")
    
    if failed_symbols:
        logger.warning(f"‚ö†Ô∏è  Falhas: {len(failed_symbols)} s√≠mbolos")
        logger.debug(f"S√≠mbolos com falha: {failed_symbols}")
    
    logger.info(f"üíæ S3 Quotes: {'‚úì' if save_results['quotes_saved'] else '‚úó'}")
    logger.info(f"üíæ S3 Fundamentais: {'‚úì' if save_results['fundamentals_saved'] else '‚úó'}")
    logger.info(f"‚è±Ô∏è  Tempo total: {execution_time:.1f} segundos")
    logger.info("=" * 50)
    
    # Retorno para Lambda
    return {
        'statusCode': 200,
        'body': json.dumps({
            'status': 'completed',
            'execution_time_seconds': round(execution_time, 2),
            'companies_total': len(symbols),
            'quotes_successful': len(successful_quotes),
            'fundamentals_successful': len(successful_fundamentals),
            'failed_symbols': failed_symbols,
            's3_save_results': save_results,
            'timestamp': current_time.isoformat()
        })
    }

# ===== C√ìDIGO PARA TESTE LOCAL =====
if __name__ == "__main__":
    """
    Teste local da Lambda Function
    """
    print("=" * 60)
    print("üß™ TESTE LOCAL - PIPELINE DE DADOS DE A√á√ïES")
    print("=" * 60)
    
    # Verificar configura√ß√£o
    if not ALPHA_VANTAGE_API_KEY or ALPHA_VANTAGE_API_KEY == 'demo':
        print("\n‚ùå ERRO: API KEY n√£o configurada!")
        print("\nConfigure a vari√°vel de ambiente:")
        print("  Windows (PowerShell):")
        print("    $env:ALPHA_VANTAGE_API_KEY='IRYWV66KYDTB6S2W'")
        print("    $env:S3_BUCKET_NAME='stock-quotes-data'")
        print("\n  Linux/Mac:")
        print("    export ALPHA_VANTAGE_API_KEY='IRYWV66KYDTB6S2W'")
        print("    export S3_BUCKET_NAME='stock-quotes-data'")
        print("\n  Ou crie um arquivo .env na raiz do projeto:")
        print("    ALPHA_VANTAGE_API_KEY=IRYWV66KYDTB6S2W")
        print("    S3_BUCKET_NAME=stock-quotes-data")
        sys.exit(1)
    
    print(f"\n‚úÖ Configura√ß√£o validada:")
    print(f"   API Key: {ALPHA_VANTAGE_API_KEY[:8]}...{ALPHA_VANTAGE_API_KEY[-4:]}")
    print(f"   S3 Bucket: {S3_BUCKET_NAME}")
    print(f"   Empresas: {len(get_all_symbols())}")
    
    # Mock context
    class MockContext:
        aws_request_id = f"local-{datetime.now().strftime('%Y%m%d%H%M%S')}"
        function_name = "stock-data-pipeline-local"
        memory_limit_in_mb = "512"
        function_version = "$LATEST"
    
    print("\n" + "=" * 60)
    print("üöÄ Iniciando execu√ß√£o local...")
    print("=" * 60)
    
    try:
        # Executar
        result = lambda_handler({}, MockContext())
        
        print("\n‚úÖ Execu√ß√£o local conclu√≠da!")
        print("\nüìä Resultados:")
        
        body = json.loads(result['body'])
        print(f"   Status: {body.get('status', 'unknown')}")
        print(f"   Tempo: {body.get('execution_time_seconds', 0):.1f}s")
        print(f"   Cota√ß√µes: {body.get('quotes_successful', 0)}/{body.get('companies_total', 0)}")
        print(f"   Fundamentais: {body.get('fundamentals_successful', 0)}")
        
        if body.get('failed_symbols'):
            print(f"   Falhas: {len(body['failed_symbols'])} s√≠mbolos")
            print(f"   Lista: {body['failed_symbols']}")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Execu√ß√£o interrompida pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå ERRO durante execu√ß√£o: {str(e)}")
        import traceback
        traceback.print_exc()